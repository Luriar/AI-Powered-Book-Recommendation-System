# AI 기반 도서 추천 시스템 - 프로젝트 요약

## 1. 개발 배경 및 목적

### 문제 인식
기존 온라인 서점 플랫폼(Amazon Kindle, Goodreads, Google Books 등)은 다음과 같은 한계가 있었습니다:
- **키워드 검색 위주**: 사용자의 감정이나 상황을 고려하지 못함
- **단순 인기 순위 추천**: 개인화 부족
- **자연어 교류 불가**: "우울할 때 읽고 싶은 책" 같은 질문에 대응 불가

### 해결 방안
본 프로젝트는 **자연어 처리(NLP)**와 **대규모 언어 모델(LLM)**을 활용하여:
- 사용자의 **감정, 상황, 독서 목적**을 이해
- **의미 기반 유사도 계산**으로 정확한 추천
- **대화형 인터페이스**로 자연스러운 사용자 경험 제공

---

## 2. 핵심 기술

### (1) AI 자동 요약 생성

**문제**: 도서 설명이 너무 길거나 없는 경우 사용자가 내용 파악 어려움

**해결**:
- **DeepSeek Reasoner API** 활용해 도서 설명을 3줄로 자동 압축
- 멀티스레드 배치 처리로 대량 요약 생성
- **성능**: 16권 처리 시간 611초 → 70초 (8.7배 개선)

**기술 구성**:
```
IsbnBatchRegistrar (도서 등록)
    ↓
Google Books API (메타데이터 수집)
    ↓
BookSummaryBatchRunner (배치 처리)
    ↓
DeepSeek API (요약 생성) + RateLimiter (호출 제어)
    ↓
MySQL 저장
```

---

### (2) 감정 기반 자연어 추천

**문제**: 사용자가 정확한 검색어를 모르거나, 감정/상황을 표현하고 싶을 때 기존 검색 시스템 한계

**해결 흐름**:
```
사용자 입력 ("시험 기간에 읽으면 좋을 책 추천해줘")
    ↓
DeepSeek-V3 (의도 분석)
  → 감정: "불안", 상황: "시험", 주제: "자기계발"
    ↓
e5-large-v2 (벡터 임베딩)
  → 사용자 입력 벡터 vs 도서 요약 벡터
    ↓
유사도 계산 (Cosine Similarity)
  + 키워드 매칭 점수
  + 사용자 관심사 가중치
    ↓
Top-5 추천 결과
```

**핵심 알고리즘**:
```
총점 = (
    0.30 × 벡터 유사도 +
    감정 가중치 × 감정 벡터 유사도 +
    상황 가중치 × 상황 벡터 유사도 +
    주제 가중치 × 주제 벡터 유사도
) × 패널티 팩터
```

**성능**:
- 추천 응답 시간: 38초 → 16.7초 (2.3배 개선)
- 임베딩 계산: 117ms → 37ms (3.2배 개선)

---

### (3) 콜드스타트 문제 해결

**문제**: 신규 사용자는 추천에 필요한 행동 데이터가 없음

**해결**:
- 회원가입 시 **최소 3개 관심 카테고리 선택** 필수
- 초기 추천 시 관심사 가중치 적용
- 첫 추천부터 개인화된 결과 제공 가능

---

## 3. 시스템 아키텍처

### 전체 구조
```
Frontend (Vue3)
    ↕ REST API
Backend (Spring Boot)
    ├─→ MySQL (사용자, 도서, 추천 기록)
    └─→ Flask AI Service
          ├─→ DeepSeek API (요약/분석)
          └─→ e5-large-v2 (벡터 임베딩)
```

### 주요 모듈
1. **사용자 관리**: 회원가입, 로그인, JWT 인증, 관심사 설정
2. **도서 관리**: ISBN 일괄 등록, 분류, 검색, 가격/재고 관리
3. **AI 요약**: 배치 처리, 멀티스레드, Rate Limiting
4. **추천 시스템**: 자연어 분석, 벡터 임베딩, 하이브리드 점수 계산
5. **수집/대출**: 위시리스트, 도서 대출/반납, 이력 조회
6. **UI/UX**: BGM 선택, 로딩 스켈레톤, 반응형 디자인

---

## 4. 성능 최적화 전략

### (1) 멀티스레드 처리
- ExecutorService (최대 40 스레드)
- AI 요약 생성 시 병렬 처리
- 611초 → 70초 (8.7배 개선)

### (2) GPU 가속
- torch.cuda 활용
- 벡터 연산 가속
- 추천 시간 38초 → 16.7초

### (3) API 호출 제어
- Guava RateLimiter (초당 4회 제한)
- DeepSeek API 과부하 방지
- 안정적인 서비스 제공

### (4) 벡터 캐싱
- 도서 벡터 사전 계산 및 캐싱
- 중복 임베딩 연산 방지
- 임베딩 시간 117ms → 37ms

### (5) 비동기 처리
- Python asyncio 활용
- DeepSeek API 병렬 호출
- 대기 시간 최소화

---

## 5. 기술 선택 과정

### LLM API 비교 분석

| API | 비용 (토큰당) | 한국어 지원 | 최종 평가 |
|-----|---------------|-------------|-----------|
| GPT-4 | $0.03 | 우수 | 성능 최고, 비용 높음 X |
| Google PaLM 2 | 무료 쿼터 | 보통 | 한국어 성능 제한적 X |
| DeepSeek | GPT-4의 1/10 | 우수 | 비용 효율 + 성능 균형 ✓ |

**최종 선택**: DeepSeek
- 학생 프로젝트로 비용 제약 존재
- 한국어/중국어 지원 우수
- API Rate Limit 유연

### 벡터 임베딩 모델 비교

| 모델 | 특징 | 최종 평가 |
|------|------|-----------|
| OpenAI Embedding | 유료 API, 성능 우수 | 비용 부담 X |
| e5-large-v2 | 오픈소스, GPU 가속 가능 | 무료 + 로컬 처리 ✓ |

---

## 6. 개발 과정 중 어려움과 해결

### (1) AI API 응답 지연

**문제**: 초기 추천 응답 시간 38초로 사용자 경험 저하

**해결**:
- GPU 가속 적용
- 벡터 사전 계산 및 캐싱
- 비동기 처리로 병렬화
- **결과**: 16.7초로 단축

### (2) 대량 요약 생성 시간

**문제**: 순차 처리로 611초 소요

**해결**:
- 멀티스레드 배치 처리 (40 스레드)
- RateLimiter로 API 과부하 방지
- **결과**: 70초로 단축

### (3) 프론트엔드 "멈춤" 느낌

**문제**: API 호출 중 화면이 멈춘 것처럼 보임

**해결**:
- 로딩 스켈레톤 추가
- 진행 상태 표시
- 에러 메시지 명확화

### (4) 외부 API 의존성

**문제**: DeepSeek API 장애 시 시스템 마비 가능

**해결**:
- 예외 처리 및 재시도 로직
- 실패 로그 기록
- 타임아웃 설정

---

## 7. 주요 성과 및 배운 점

### 정량적 성과

| 항목 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| AI 요약 생성 (16권) | 611초 | 70초 | **8.7배** |
| 추천 응답 시간 | 38초 | 16.7초 | **2.3배** |
| 임베딩 계산 | 117ms | 37ms | **3.2배** |

### 정성적 성과
- 자연어 기반 추천 정확도 높음 (5/5 "매우 만족" 평가)
- 콜드스타트 문제 해결
- 완전한 온라인 서점 기능 구현

### 배운 점

#### 1) AI 기술 선택 전략
- 비용과 성능의 균형점 찾기
- 프로젝트 규모와 예산에 맞는 기술 선택
- 오픈소스 활용으로 비용 절감

#### 2) 성능 최적화 사고방식
- 병목 지점 정확한 측정 (로그 분석)
- 멀티스레드, GPU, 캐싱 등 다각도 접근
- 최적화 전후 정량적 비교

#### 3) 전체 시스템 설계 역량
- 모듈화와 낮은 결합도 유지
- RESTful API 설계 원칙 준수
- 프론트엔드/백엔드/AI 서비스 분리

#### 4) 사용자 중심 사고
- 기술보다 사용자 경험 우선
- "멈춘 느낌" 제거 (로딩 표시, 피드백)
- 자연어 인터페이스로 진입 장벽 낮춤

---

## 8. 향후 개선 방향

### 단기 개선 계획
1. **사용자 피드백 학습**
   - 클릭/건너뛰기 행동 수집
   - 추천 정확도 지속 향상

2. **모바일 반응형 디자인**
   - 현재 PC 중심 → 모바일 최적화
   - 터치 인터페이스 개선

3. **벡터 DB 도입**
   - MySQL → Pinecone/Milvus
   - 벡터 검색 성능 향상

### 장기 확장 계획
1. **로컬 LLM 배포**
   - API 의존도 감소
   - 비용 절감 및 안정성 향상

2. **다국어 지원**
   - 영어, 일본어 등 확장
   - 글로벌 서비스 가능성

3. **협업 필터링 추가**
   - 사용자 간 유사도 기반 추천
   - 하이브리드 추천 고도화

---

## 9. 프로젝트 정보

### 개발 환경
- **Backend**: Spring Boot 3.0, JPA, MySQL 8.0
- **Frontend**: Vue 3, Axios, Pinia
- **AI/ML**: DeepSeek API, PyTorch, e5-large-v2
- **Infra**: Flask, Guava RateLimiter

### 개발 기간 및 역할
- **기간**: 2024년 11월 ~ 2025년 5월 (6개월)
- **역할**: 단독 개발 (기획, 설계, 구현, 테스트)
- **학교**: 북경과학기술대학교 컴퓨터공학과
- **학술 성과**: 졸업논문 심사 통과 예정 (2025년 6월)

### 참고 자료
- **원본 졸업논문** (중국어, 60페이지): [graduation_thesis_CN.pdf](./graduation_thesis_CN.pdf)
- **시스템 아키텍처**: 논문 3장 참조
- **API 명세서**: 논문 4.2절 참조
- **성능 테스트 결과**: 논문 5장 참조

---

**작성자**: 윤준호  
**작성일**: 2025년 5월  
**연락처**: joonhoeric01@gmail.com
